{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0307b025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import nflreadpy as nfl\n",
    "import nfl_data_py as nfl_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c52f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NFL data fo2 2025 season\n",
    "season = 2025\n",
    "schedule = nfl.load_schedules(seasons=[season])\n",
    "schedule = schedule.to_pandas()\n",
    "\n",
    "# Select only regular season games, create target variable\n",
    "games = schedule[schedule['game_type'] <= 'REG'].copy()\n",
    "games[\"winner\"] = (games[\"home_score\"] > games[\"away_score\"]).astype(int) # 1 if home team wins, 0 if away team wins\n",
    "team_stats = nfl.load_team_stats([season])\n",
    "team_stats = team_stats.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for EPA per play\n",
    "team_stats[\"pass_plays\"] = team_stats[\"attempts\"] + team_stats[\"sacks_suffered\"]\n",
    "team_stats[\"rush_plays\"] = team_stats[\"carries\"]\n",
    "team_stats[\"total_plays\"] = team_stats[\"pass_plays\"] + team_stats[\"rush_plays\"]\n",
    "team_stats[\"off_epa_per_play\"] = (\n",
    "    (team_stats[\"passing_epa\"] * team_stats[\"pass_plays\"]) +\n",
    "    (team_stats[\"rushing_epa\"] * team_stats[\"rush_plays\"])\n",
    ") / team_stats[\"total_plays\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns points for and against to team_stats\n",
    "home = schedule[[\"season\", \"week\", \"home_team\", \"away_team\", \"home_score\", \"away_score\"]].copy()\n",
    "home[\"team\"] = home[\"home_team\"]\n",
    "home[\"points_for\"] = home[\"home_score\"]\n",
    "home[\"points_against\"] = home[\"away_score\"]\n",
    "\n",
    "away = schedule[[\"season\", \"week\", \"home_team\", \"away_team\", \"home_score\", \"away_score\"]].copy()\n",
    "away[\"team\"] = away[\"away_team\"]\n",
    "away[\"points_for\"] = away[\"away_score\"]\n",
    "away[\"points_against\"] = away[\"home_score\"]\n",
    "\n",
    "schedule_long = pd.concat([home, away], ignore_index=True)\n",
    "\n",
    "# Merge into team_stats\n",
    "team_stats = team_stats.merge(\n",
    "    schedule_long[[\"season\", \"week\", \"team\", \"points_for\", \"points_against\"]],\n",
    "    on=[\"season\", \"week\", \"team\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85cb15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for turnover differential\n",
    "# Offensive giveaways\n",
    "team_stats[\"giveaways\"] = (\n",
    "    team_stats[\"passing_interceptions\"] + \n",
    "    team_stats[\"rushing_fumbles_lost\"] + \n",
    "    team_stats[\"receiving_fumbles_lost\"] + \n",
    "    team_stats[\"sack_fumbles_lost\"]\n",
    ")\n",
    "\n",
    "# Defensive takeaways\n",
    "team_stats[\"takeaways\"] = (\n",
    "    team_stats[\"def_interceptions\"] + \n",
    "    team_stats[\"fumble_recovery_opp\"]   # opp fumbles recovered by your team\n",
    ")\n",
    "\n",
    "# Turnover differential\n",
    "team_stats[\"turnover_diff\"] = team_stats[\"takeaways\"] - team_stats[\"giveaways\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5601d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scrape defensive EPA/play from https://sumersports.com/teams/defensive/\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://sumersports.com/teams/defensive/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table containing the defensive stats\n",
    "table = soup.find('table')\n",
    "\n",
    "headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "\n",
    "# Extract rows\n",
    "rows = []\n",
    "for tr in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    cols = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "    if cols:  # Ensure the row is not empty\n",
    "        rows.append(cols)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "# Clean up the team names (remove extra spaces)\n",
    "df['team'] = df['Team'].str.replace(r'^\\d+\\.\\s*', '', regex=True)\n",
    "df['EPA/Play'] = pd.to_numeric(df['EPA/Play'], errors='coerce')\n",
    "\n",
    "def_epa_df = df[['team', 'EPA/Play']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30af6c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Team 2025_Offense 2025_Defense\n",
      "0           Miami       54.29%       52.63%\n",
      "1       Green Bay       53.70%       32.73%\n",
      "2   San Francisco       48.08%       32.00%\n",
      "3         Chicago       45.45%       29.27%\n",
      "4     LA Chargers       43.40%       38.33%\n",
      "5          Dallas       42.55%       58.18%\n",
      "6         Buffalo       42.00%       42.00%\n",
      "7    Philadelphia       41.82%       36.96%\n",
      "8         Atlanta       41.82%       34.09%\n",
      "9     New England       41.67%       39.13%\n",
      "10        Detroit       41.51%       41.67%\n",
      "11     Cincinnati       41.03%       46.34%\n",
      "12      Baltimore       40.91%       41.94%\n",
      "13        LA Rams       40.43%       34.00%\n",
      "14   Indianapolis       39.58%       40.00%\n",
      "15    Kansas City       39.29%       34.04%\n",
      "16        Seattle       39.13%       38.98%\n",
      "17     Pittsburgh       38.64%       41.82%\n",
      "18        Arizona       38.46%       34.62%\n",
      "19       Carolina       38.18%       37.21%\n",
      "20      Cleveland       37.70%       44.83%\n",
      "21      Tampa Bay       37.04%       32.65%\n",
      "22    New Orleans       35.85%       42.55%\n",
      "23      Las Vegas       35.85%       39.22%\n",
      "24   Jacksonville       35.19%       45.61%\n",
      "25     Washington       33.33%       33.33%\n",
      "26      NY Giants       32.73%       42.31%\n",
      "27         Denver       32.43%       36.36%\n",
      "28      Minnesota       30.61%       33.33%\n",
      "29        Houston       29.17%       35.85%\n",
      "30        NY Jets       27.78%       35.14%\n",
      "31      Tennessee       27.78%       38.00%\n"
     ]
    }
   ],
   "source": [
    "# Web scrape 3rd down conversion % (offense and defense) from https://www.teamrankings.com/\n",
    "urls = {\n",
    "    'third_down': 'https://www.teamrankings.com/nfl/stat/third-down-conversion-pct',\n",
    "    'opponent_third_down': 'https://www.teamrankings.com/nfl/stat/opponent-third-down-conversion-pct'\n",
    "}\n",
    "\n",
    "# Function to scrape data from a given URL\n",
    "def scrape_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the stats\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Extract headers\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "\n",
    "    # Extract rows\n",
    "    rows = []\n",
    "    for tr in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        cols = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "        if cols:  # Ensure the row is not empty\n",
    "            rows.append(cols)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    # Clean up the team names (remove extra spaces)\n",
    "    df['Team'] = df['Team'].str.strip()\n",
    "\n",
    "    return df[['Team', '2025']]\n",
    "\n",
    "# Scrape data for both statistics\n",
    "third_down_df = scrape_data(urls['third_down'])\n",
    "opponent_third_down_df = scrape_data(urls['opponent_third_down'])\n",
    "\n",
    "# Merge the dataframes on the 'Team' column\n",
    "merged_df = pd.merge(third_down_df, opponent_third_down_df, on='Team', suffixes=('_Offense', '_Defense'))\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c33799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with rolling averages of relevant features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nflmodel)",
   "language": "python",
   "name": "nflmodel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
